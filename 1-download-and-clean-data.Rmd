---
title: "1-download-and-clean-data.Rmd"
author: "Seth Green and John-Henry Pezzuto"
date: "8/14/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

### setup
```{r setup}
rm(list = ls())
library(dplyr, warn.conflicts = FALSE)
library(googledrive)
library(readr)
library(tidyr)
options(scipen = 99)
```

### Download most up to date dataset
```{r download_data}
## download sheet from google -----------------------------------
drive_auth(email = T)
drive_download("Primary Prevention Meta 2020", 
               path = "./data/sa_meta_data",
               overwrite = T, type = 'csv') # dl to csv gets just first sheet
```


```{r clean_data}
raw_dat <- read.csv('./data/sa_meta_data.csv', na.strings = c("NA"))
readr::problems(raw_dat)
# drop redline studies and add unique paper ID
raw_dat <- raw_dat %>%
  fill(paper_title) %>%
  filter(!is_red %in% c("#ff0000", "#ea4335", "#f4cccc"))  %>%  # in case multiple red cols
  group_by(paper_title) %>%
  mutate(first_line = row_number() == 1) %>%
  ungroup() %>%
  mutate(unique_paper_id = cumsum(first_line))

#' drop team-internal stuff 
colnames(raw_dat)
raw_dat <- raw_dat %>% 
  select(-c(coder, page_number, comments, d, var_d, se_d, checked, checker_comment, first_line))
```

#' prepare Cohen's D calcs

making sure that inputs are all what the functions expect: eff_type, cluster_type, and checking for NAs

```{r standardizing_inputs}
unique(raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'd.i.d', replacement = 'd_i_d', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'f.test', replacement = 'f_test', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'd.i.m', replacement = 'd_i_m', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'difference_in_proportion', replacement = 'd_i_p', x = raw_dat$eff_type)
# raw_dat$eff_type <- gsub(pattern = 'reg.coef (B)', replacement = 'reg_coef', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'reg.coef', replacement = 'reg_coef', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 't.test', replacement = 't_test', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'beta', replacement = 'reg_coef', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'log.odds.ratio', replacement = 'log_odds_ratio', x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'odds.ratio', replacement = 'odds_ratio', x = raw_dat$eff_type)
# raw_dat$eff_type <- gsub(pattern = '', replacement = NA, x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'NA', replacement = NA, x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = '-', replacement = NA, x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'did', replacement = "d_i_d", x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'dim', replacement = "d_i_m", x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = "^$|^ $", replacement =  NA, x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'd.i.p', replacement = "d_i_p", x = raw_dat$eff_type)
raw_dat$eff_type <- gsub(pattern = 'd.i.p.', replacement = "d_i_p", x = raw_dat$eff_type)


# fix cluster type data
raw_dat$cluster_type <- gsub('n_groups', 'n groups', raw_dat$cluster_type)
raw_dat$cluster_type <- gsub('-', NA, raw_dat$cluster_type)
raw_dat$cluster_type <- gsub("^$|^ $", NA, raw_dat$cluster_type)

## how many of these are going to require non-standard procedures
## or potential re-doing of the recording
table(raw_dat$eff_type, useNA = 'ifany') # there were 15 NAs but as of 06/18/21
# everything is accounted for; notes on specifics in slack conversation  with 
# JH & Roni. For each, I either pinklined them (re: recommended for redline) or filled them in
```

#' Ns, anticipated directions, and ctrl_SDs

```{r fix_vars }
class(raw_dat$ctrl_sd)
table(raw_dat$ctrl_sd)

which(raw_dat$ctrl_sd == "") # as of 06/18/2021, this is no rows, because
# I fixed a bunch of studies' 'is_red' tab not being up to date

# TODO: We should just move all the redlined studies to a different tab
#' convert "no.sd" and "-" to NA
raw_dat$ctrl_sd <- gsub(pattern = 'no.sd', replacement = NA, x = raw_dat$ctrl_sd)
raw_dat$ctrl_sd <- gsub(pattern = '-', replacement = NA, x = raw_dat$ctrl_sd)
table(raw_dat$ctrl_sd)

#' Before convert to numeric,check which  will be converted to NA "by coercion" 
sum(which(is.na(as.numeric(raw_dat$ctrl_sd))) != which(is.na(raw_dat$ctrl_sd)))
# as of 6/18/2021. there are no studies converted by coercion
# note: if there are some, re-download the data
raw_dat$ctrl_sd <- as.numeric(raw_dat$ctrl_sd)

#' Convert all ctrl_SDs to 1 when Cohen's D is eff_type
#' probably not strictly necessary but good practice to note this
raw_dat <- raw_dat %>% 
  mutate(ctrl_sd = if_else(condition = (eff_type == 'd'),
                           true = 1, false = ctrl_sd))

## are there any ctrl_sds that are NA when that's going to break the calculator?
na_dat <- raw_dat %>% filter(is.na(ctrl_sd)) %>%
  filter(eff_type == 'd_i_d' | eff_type == 'd_i_m') %>%
    select(author, year, paper_title, eff_type, u_s_d, ctrl_sd,
         n_t_post, n_c_post, n_t_group, n_c_group,
         unique_paper_id, intervention_name,
         study_design, scale_name, is_red)
## TODO: every one of the above studies needs a closer look; Fortunately they're all
# either quasi-experimental or prepost (except for two from Foshee but that's just that)
# the redline thing isn't working consistently, some studies are coming through as
# is_red = 'loading' 
# Probably a lot of these should have been reported as unspecified nulls

#' FOR NOW: drop all the messy stuff for now as we prepare for meta-analysis

table(raw_dat[is.na(raw_dat$ctrl_sd),]$eff_type, useNA = 'ifany')  
which(!is.na(raw_dat$ctrl_sd) & is.na(raw_dat$eff_type)) # 0 as of 06/18
table(raw_dat$eff_type)
range(raw_dat$u_s_d, na.rm = T) 

## change the cluster randomized var to be factors with an NA rather than a -
raw_dat$cluster_type <- gsub(pattern = '-', replacement = NA, x = raw_dat$cluster_type)

## make everything else we need numeric
raw_dat$n_t_pre <- gsub(pattern = '-', replacement = NA, x = raw_dat$n_t_pre)
raw_dat$n_t_post <- gsub(pattern = '-', replacement = NA, x = raw_dat$n_t_post)
raw_dat$n_c_pre <- gsub(pattern = '-', replacement = NA, x = raw_dat$n_c_pre)
raw_dat$n_c_post <- gsub(pattern = '-', replacement = NA, x = raw_dat$n_c_post)
raw_dat$n_t_group <-  gsub(pattern = '-', replacement = NA, x = raw_dat$n_t_group)
raw_dat$n_c_group <-  gsub(pattern = '-', replacement = NA, x = raw_dat$n_c_group)

# not given
raw_dat$n_c_group <-  gsub(pattern = 'not given', replacement = NA, x = raw_dat$n_c_group)
raw_dat$n_t_group <-  gsub(pattern = 'not given', replacement = NA, x = raw_dat$n_t_group)

# class(raw_dat$n_c_post)
# table(raw_dat$n_c_post)
# table(raw_dat$n_t_pre)

Ns <- raw_dat %>%
  select(n_t_pre, n_t_post, n_c_pre, n_c_post, n_t_group, n_c_group)

raw_dat <- raw_dat %>%
  mutate(across(.cols = c(starts_with(c('n_t_', 'n_c_'))), .fns = as.numeric) %>% 
  mutate(u_s_d = as.numeric(u_s_d)) %>%
  mutate(anticipated_direction = as.numeric(anticipated_direction)))
# TODO: revisit these warnings
na_vals <- raw_dat %>% filter(is.na(anticipated_direction) |
                                is.na(across(.cols = c(starts_with('n_'))))) %>%
    select(author, year, paper_title, eff_type, u_s_d, ctrl_sd,
           n_t_pre, n_c_pre,
         n_t_post, n_c_post, n_t_group, n_c_group,
         unique_paper_id, intervention_name,
         study_design, scale_name)
# these are all fine -- enough info to calculate Cohen's D
rm(na_vals)

# check lab/field variable
unique(raw_dat$lab_field)
sum(is.na(raw_dat$lab_field)) # 0 as of 09/19
raw_dat$lab_field <- as.factor(raw_dat$lab_field)
```

# fix study_design var
and scale type


```{study_design}
raw_dat$study_design <- gsub(pattern = 'cross sectional', replacement = 'cross-sectional',  x = raw_dat$study_design)
raw_dat$study_design <- gsub(pattern = 'prepost', replacement = 'pre-post',  x = raw_dat$study_design)
raw_dat$study_design <- as.factor(raw_dat$study_design)

raw_dat <- raw_dat %>% 
  select(-lab_or_field)
# ADD IS_RED at the end

# scale type
raw_dat$scale_type <- as.factor(raw_dat$scale_type)
```

### add pragmatic rct designation
Also make some just quasi-experimental because t=otherwise they really won't work for calculating variance
```{r pragmatic_rct}
raw_dat$study_design <- as.character(raw_dat$study_design)
table(raw_dat$study_design)
raw_dat <- raw_dat %>%
  mutate(study_design = case_when(
    !is.na(n_t_group) &
      study_design == 'rct' &
      n_t_group + n_c_group <= 3 ~ 'quasi-experimental',
    !is.na(n_t_group) &
      study_design == 'rct' & 
      between(n_t_group + n_c_group, 4, 10) ~ 'pragmatic rct',
    TRUE ~ study_design))

raw_dat$study_design <- as.factor(raw_dat$study_design)


table(raw_dat$study_design)
# Foshee 1998 -- should be 7 and 7 in n_t and n_c
# so the D calculation needs to be modified to say, if cluster + rct, 
# n = n_t_group, n_c_group
```

### unique study id
```{r}
raw_dat <- raw_dat %>%
  group_by(unique_paper_id, intervention_name) %>% 
  mutate(unique_study_id = cur_group_id())
# based this on https://stackoverflow.com/questions/62562499/obtain-a-unique-id-by-group-in-mutate-pipeline
# hope it's right
```
### fix delay

```{r delay}
# TODO: double-check dat$delay. it's a string vector and we need to convert everything to days. 
# I'm doing a lubridate thing here but obviously this is not perfect
# I am assuming that NA = 0 days because if we had that info, we'd record it. 
# I know there's a better way to do this and I will consult with JH

# raw_dat$delay <- gsub(NA, '0', raw_dat$delay)
# raw_dat$delay <- gsub('NA', '0', raw_dat$delay

raw_dat$delay <- gsub('4 month', '122', raw_dat$delay)
raw_dat$delay <- gsub('2.5 years', '912.5', raw_dat$delay)
raw_dat$delay <- gsub('2 weeks', '14', raw_dat$delay)
raw_dat$delay <- gsub('3 weeks', '21', raw_dat$delay)
raw_dat$delay <- gsub('1 month', '30.5', raw_dat$delay)
raw_dat$delay <- gsub('5 weeks', '35', raw_dat$delay)
raw_dat$delay <- gsub('14 days', '14', raw_dat$delay)

raw_dat$delay[is.na(raw_dat$delay)] = "0"

table(raw_dat$delay)
raw_dat$delay <- as.numeric(raw_dat$delay)

```

### is_red: loading?
```{r is_red}
raw_dat %>% filter(is_red == "Loading...")
# GENERAL CHECK: make sure there are no rows that meet this condition

raw_dat <- raw_dat %>% select(-is_red)


```

There's more cleaning that could be done -- All marked with TODOs in the above text, or in subsequent files -- , but if I'm not mistaken, we can go ahead with the core parts of the analysis and return to this.

For now, save as clean data and start the Cohen's D script
```{r save_clean_data}

saveRDS(object = raw_dat, file = './data/sa_meta_data_cleaned.rds')
```