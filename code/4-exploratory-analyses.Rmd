---
title: "4-exploratory-analyses"
author: "Seth Green"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
editor_options: 
  chunk_output_type: console
---
## Setup 

```{r setup, echo=F}
rm(list = ls())
library(dplyr, warn.conflicts = F)
library(knitr)
library(metafor, quietly = T)
library(ggplot2, warn.conflicts = F)
library(ggrepel, warn.conflicts = F)
library(lubridate)
library(purrr)
library(stringr)
library(tidyr, warn.conflicts = F)
library(tibble)

source('./functions/sum_lm.R')
source('./functions/map_robust.R')
source('./functions/study_count.R')
source('./functions/dplot.R')

options(scipen = 99)
```

**load data**

```{r load_data, echo=F}
dat <- readRDS(file = '../data/sa_meta_data_final.rds') |>
  select(unique_study_id, scale_type, everything())
```

### bystander interventions are a product of their time and place
```{r bystander_interventions_over_time}

bystander_dat <- dat |>
  filter(
    str_detect(paper_title, "bystander") |
      str_detect(brief_description_of_the_intervention, "bystander") |
      str_detect(intervention_name, "bystander") |
      str_detect(program_name, "bystander") |
      str_detect(stated_purpose, "4")) |>
    select(author, year, paper_title, unique_study_id, study_design,
           d, var_d, se_d, scale_type,
           behavior_type, has_both, country) |>
  mutate(perp_vict_grouped = case_when(
    behavior_type == 'Victimization' | behavior_type == 'Perpetration' ~ 'perp_vict',
    behavior_type == 'Involvement' ~ 'involvement',
    behavior_type == 'Attitude' ~ 'Attitude',
    behavior_type == 'Bystander' ~ 'Bystander'))

bystander_dat |> group_by(unique_study_id) |> slice(1) |> ungroup() |>
  ggplot(aes(x = year)) +
  geom_line(stat = 'count', color = 'light blue') + 
  labs(x = "Year", 
       y = "Count", 
       title = "Bystander interventions over time") +
  # scale_x_date(date_breaks = "2 years") +
  scale_x_continuous(n.breaks = 20) +
  scale_y_continuous(n.breaks = 15) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

## BTW an alternate way to do this
dat |>
  group_by(unique_study_id) |>
  summarise(
    bystander_count = ifelse(
      any(
        str_detect(c(
          brief_description_of_the_intervention, 
          intervention_name, program_name, paper_title), "bystander")) |
        any(str_detect(stated_purpose, "4")),
      TRUE, FALSE)
  ) |> 
  summarise(
    bystander = sum(ifelse(is.na(bystander_count), FALSE, bystander_count)),
    no_bystander = sum(ifelse(is.na(bystander_count), TRUE, !bystander_count))
  )

# where do bystander interventions occur
bystander_dat |> group_by(country) |> study_count()
```

## alternative correlation scatterplot
```{r alt_corr_scatterp}
dat |> 
  filter(has_both == 'both') |> 
  drop_na(study_design) |> 
  group_by(author, year, study_design, unique_study_id, scale_type) |>
  summarise(mean_d = mean(d), 
         mean_var_d = mean(var_d), 
         mean_se_d = mean(se_d)) |> 
  pivot_wider(id_cols = c(author, year, unique_study_id, study_design),
    names_from = c(scale_type), 
    values_from = c(mean_d, mean_var_d, mean_se_d)) |>
  ggplot(aes(x = mean_d_attitudes,
             y = mean_d_behavior)) + 
  geom_point(aes(color = study_design),
             size = 3) + 
  geom_abline(slope = 1, 
              lty = 'dashed',
              linewidth = 2) +
  geom_smooth(lty = "dashed", 
              method = "lm", 
              se = FALSE,
              color = 'grey',
              linewidth = 2) +  
    labs(x = "Effect size (Ideas)",
       y = "Effect size (Behaviors)",
       color = NULL) +
  scale_x_continuous(breaks = seq(-.5, 1.5, by = .5), limits = c(-.5,1.6)) +
  scale_y_continuous(breaks = seq(-.5, 1.5, by = .5), limits = c(-.5,1.6)) +
  scale_color_manual(values = ggthemes::stata_pal("s2color")(3)) +
  theme_bw() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    legend.text = element_text(size = 14),
    legend.position = "bottom",
    legend.box = "vertical"
  )
```

Here was a rough idea for a 'figure 1' analogous to the D/SE plot in the contact hypothesis paper

```{r d_se_plot}
dat |>
  drop_na(study_design) |> 
  ggplot(aes(x = se_d, y = d)) +
  geom_point(aes(color = behavior_type,
                 shape = study_design),
             size = 3) +
  geom_smooth(method = "lm",
              se = F) +
  #ggtitle("Relationship between effect sizes and standard errors") +
  labs(x = "Standard errors",
       y = "Effect size",
       color = "Outcome type",
       shape = "Study Design") +
  theme_bw() +
  theme(axis.text = element_text(size = 12),
        legend.text = element_text(size = 12),
        legend.position = "bottom",
        legend.box = "vertical")
# alternatiely, just 
dplot(condense = F)

# alternative where we separate by outcome type
dat |> ggplot(mapping = aes(y = d, 
                             x = se_d)) + 
  geom_point(aes(color = behavior_type,
             shape = study_design),
             size = 3) + 
  stat_smooth(method = 'lm', se = F) + 
  ggtitle("Relationship between effect sizes and standard errors") +
  labs(x = "Standard errors",
       y = "Effect size",
       color = "Outcome type",
       shape = "Study Design") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

```



```{r att_beh_breakdown}


dat |> 
  group_by(has_both) |>
  study_count()

# sanity check
length(unique(dat$unique_study_id)) == 207 + 36 + 61 # true
```

Some further attempts to assess relationship between SE and D within different study design subsets
```{r viz_attempts}
dat |> 
  split(~study_design) |> 
  map(.f = ~dplot(sa_data = ., dot_size = 2, condense = F,
                          dot_informative = T))
 
```

Here's a much messier way of slicing the data to get at the relationship between attitudinal and behavioral change
```{r att_beh_change}

## Relationship between attitudes and behaviors 
has_both <- dat |> filter(has_both == 'both') |> 
  group_by(unique_study_id, scale_type) |>
  mutate(mean_d = mean(d), 
         mean_var_d = mean(var_d), 
         mean_se_d = mean(se_d)) |>
  select(author, year, paper_title, unique_study_id, intervention_name,
         study_design, mean_d, mean_var_d, mean_se_d,
         ra, labels, scale_type, decade, behavior_type) |>  
  slice(1) |> 
  pivot_wider(
    id_cols = c(author, year, paper_title, unique_study_id,
                intervention_name,
                unique_study_id, study_design, ra, labels, decade),
    names_from = c(scale_type), 
    values_from = c(mean_d, mean_var_d, mean_se_d))

has_both |>
  ggplot(aes(x = mean_d_attitudes, 
             y = mean_d_behavior,
             color = study_design)) +
  geom_point(size = 3) + 
  geom_smooth(method = 'lm', se = F, lty = 'dashed') + 
  theme_minimal()

# now same with RCTs, and with study labels
has_both |> 
  filter(study_design == 'Randomized Control Trial') |> 
  ggplot(mapping = aes(x = mean_d_attitudes, y = mean_d_behavior)) +
  geom_point(size = 3, color = 'blue') + 
  geom_smooth(aes(fill = NULL), lty = "dashed", fullrange = TRUE,
              method = "lm",
              show.legend = FALSE, alpha = .1, se = F) +
  geom_label_repel(mapping = aes(label = labels)) +
  theme_minimal() +
  labs(x = "mean d (attitudes)",
       y = "mean d (behavior)")
# hard to read in a paper but maybe a good starting point for looking into papers that 
# have or do not have a strong correlation between attitude and behavior change
```

### Robustness checks

Group results within study

```{r grouping rbustness checks}
# robustness check: group by study AND scale_type and average the results
dat_grouped <- dat |>
  group_by(unique_study_id, scale_type) |>
  mutate(mean_d = mean(d),
         mean_var_d = mean(var_d),
         mean_se_d = mean(se_d)) |>
  slice(1)

robust(x = rma(yi = d, vi = var_d, data = dat_grouped),
       cluster = dat_grouped$unique_study_id)

# alternative specification 
rma(yi = d, vi = var_d, data = dat_grouped)

# once we've grouped by study_id, clustering changes the SE by just 0.0001

# How about not grouping by scale_type/
dat_grouped_two <- dat |>
  group_by(unique_study_id) |>
  mutate(mean_d = mean(d),
         mean_var_d = mean(var_d),
         mean_se_d = mean(se_d)) |>
  slice(1)

robust(x = rma(yi = d, vi = var_d, data = dat_grouped_two),
  cluster = dat_grouped_two$unique_study_id)
```

different ways to break down main results:
```{r alternate_breakdowns}
# ra vs not (in paper we break down by study)
dat |> 
  split(~interaction(scale_type, ra)) |>   
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# We *would* include this next outcome if our behavioral category table 
# included an 'overall' row

dat |> 
  split(~behavior_type) |> 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id)) 
# this suggests that moving the needle on perpetration is effectively unsolved problem

# in general, the effects on victimization and  perpetration are larger in the rcts, 
# which is encouraging (and surprising to me).

table(dat$behavior_type)
# TODO: triple-check that thesse are right.

# scale type and delay
dat |> 
  split(~interaction(scale_type,yes_delay)) |> 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
```

sum_lm() checks that don't make it into the final paper

```{r sum_lm checks}
dat |>  
  split(~ra) |>  # ra = random assignment (so RCTs vs. everything else)
  map(.f = ~sum_lm(y = d, x = se_d, dat = .))


# how about the overall relationship between lab/field and d? 
sum_lm(dat, d, lab_field)

# study type?
sum_lm(dat, d, study_design)
# yep, meaningful relationship

# scale type?
sum_lm(dat, d, scale_type)
# that is a HUGE difference

# publication status?
sum_lm(dat, d, publication_type)

dat |>
  filter(behavior_type == 'Perpetration', 
         study_design == 'Randomized Control Trial') |> 
  sum_lm(d, se_d)
```

Correlation between attitudes and behaviors -- standard errors of estimates

```{r attitude_behavior_correlation_standard_error}
# thank you https://stackoverflow.com/questions/16097453/how-to-compute-p-value-and-standard-error-from-correlation-analysis-of-rs-cor
cor.test.plus <- function(x) {
  list(x, 
       Standard.Error = unname(sqrt((1 - x$estimate^2)/x$parameter)))
}
cor.test.plus(
  cor.test(
    x = has_both$mean_d_attitudes, 
    y = has_both$mean_d_behavior))
```

Different ways of assessing effect size change over time

```{r effect_size_over_time}
dat |> ggplot((aes(x = year, y = d))) + 
  geom_point() +   
  geom_smooth(method = 'lm') + 
  theme_minimal()
# basically no slope

dat |> sum_lm(d, year)
dat |> split(~interaction(ra, scale_type)) |>
  map(~ ggplot(data = ., mapping = aes(x = year, y = d)) + 
        geom_point() + 
        geom_smooth(method = 'lm') +
        theme_minimal())
# more or less the same results as  Anderson, L. A., & Whiston, S.C. (2005)
```

attitudes and behavior effect sizes over time 

```{r att_beh_over_time}
dat |> 
  group_by(year, scale_type) |> 
  summarise(mean_d = mean(d), 
            mean_se_d = mean(se_d)) |>
  ggplot(aes(x = year, y = mean_d, 
             group = scale_type)) +
  geom_point(aes(color = scale_type)) +
  geom_smooth(method = 'lm', aes(color = scale_type), se = F) + 
  theme_minimal() +
  scale_x_continuous(breaks = seq(1986, 2018, 5)) +
    labs(x = "year",
       y = "mean d") +
  labs(color = "Attitudes or behaviors")
# both seem to be trending up, more behaviors than attitudes
# how much is this b/c of bystander and involvement outcomes?

dat |> 
  filter(behavior_type != "Bystander", behavior_type != 'Involvement') |>
  group_by(year, scale_type) |> 
  summarise(mean_d = mean(d), 
            mean_se_d = mean(se_d)) |>
  ggplot(aes(x = year, y = mean_d, 
             group = scale_type)) +
  geom_point(aes(color = scale_type)) +
  geom_smooth(method = 'lm', aes(color = scale_type), se = F) + 
  theme_minimal() +
  scale_x_continuous(breaks = seq(1986, 2018, 5)) +
    labs(x = "year",
       y = "mean d") +
  labs(color = "Attitudes or behaviors")
# indeed slope goes down, but still up. interesting
```


additional ways to look at rct perp outcomes

```{r rct_perp}
# not a big difference
rct_perp <- dat |> filter(study_design == 'Randomized Control Trial',
                          behavior_type == 'Perpetration')
rct_perp |> ggplot(mapping = aes(x = delay, y = d)) + 
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_minimal()

rct_perp |> filter(delay > 30) |>
ggplot(mapping = aes(x = se_d, y = d)) + 
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_minimal()
# a stronger relationship
```


### Quintile check
```{r quintile}
dat |> arrange(n_t_post) |>
  mutate(quintile = ntile(n_t_post, 5)) |> 
  group_by(unique_paper_id, intervention_name) |> 
  split(~quintile) |>
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
                   cluster = .x$unique_study_id))

# just reinforces that there's no meaningful relationship between d and se; if anything the largest decile seems to have the largest effect sizes
```


What is the 'bringing in the bystander' average effect on attitudes/behaviors

```{r repeat_tests}

dat |> 
  filter(intervention_name == "bringing in the bystander")|> 
  split(~scale_type) |> 
  map(map_robust)
# a nice todo would be to modify map_robust so that if there weren't enough 
# rows in a set it would just tell you that and continue on with the meta-analysis
# instead of stopping but, for now;

dat |> 
  filter(intervention_name == "bringing in the bystander") %>% select(behavior_type)
# so it's pretty much all bystander, with one victmization outcome
dat |> 
  filter(intervention_name == "bringing in the bystander",
         behavior_type == 'Victimization') |> 
  select(paper_title, year, d, se_d)
# d = 0,02
```

A forest plot we ultimately did not end up including

dat for forest plot and sign tests:

```{r forest_plot_dat_and_sign_tests}
dat_for_forest_plot <- dat |> 
  select(unique_study_id, scale_type, everything()) |>
  filter(study_design == 'Randomized Control Trial') |>
  group_by(unique_study_id) |>
         filter(all(c('attitudes', 'behavior') %in% scale_type)) |>
  mutate(study_names = paste0(tools::toTitleCase(word(author)), " ",
                              year, " ", "(", scale_type, ")")) |>
  group_by(unique_paper_id, scale_type) |>
  mutate(d = mean(d), var_d = mean(var_d), se_d = mean(se_d)) |>
  slice(1) |>
  ungroup(scale_type) |> 
  mutate(mean_se = mean(se_d)) |>
  arrange(mean_se) |>
  ungroup() |>
  select(study_names, d, se_d, var_d,
         scale_type, unique_study_id, unique_paper_id)

# sign test: how many studies have an attitude d that's > behavior d
dat_for_forest_plot |> group_by(unique_paper_id) |>
  summarise(mean_d_attitude = mean(d[scale_type == "attitudes"]),
            mean_d_behavior = mean(d[scale_type == "behavior"])) |>
  mutate(comparison = case_when(
    mean_d_attitude > mean_d_behavior ~ "Higher",
    mean_d_attitude == mean_d_behavior ~ "Same",
    mean_d_attitude < mean_d_behavior ~ "Lower"
  )) |>
  count(comparison) |>
  rename(Comparison = comparison, Count = n)
binom.test(15, 21, 0.5)

# now the whole thing but not filtering on RCTs

readRDS(file = '../data/sa_meta_data_final.rds') |> 
  select(unique_study_id, scale_type, everything()) |>
  group_by(unique_study_id) |>
         filter(all(c('attitudes', 'behavior') %in% scale_type)) |>
  mutate(study_names = paste0(tools::toTitleCase(word(author)), " ",
                              year, " ", "(", scale_type, ")")) |>
  group_by(unique_paper_id, scale_type) |>
  mutate(d = mean(d), var_d = mean(var_d), se_d = mean(se_d)) |>
  slice(1) |>
  ungroup(scale_type) |> 
  mutate(mean_se = mean(se_d)) |>
  arrange(mean_se) |>
  ungroup() |>
    group_by(unique_paper_id) |>
  summarise(mean_d_attitude = mean(d[scale_type == "attitudes"]),
            mean_d_behavior = mean(d[scale_type == "behavior"])) |>
  mutate(comparison = case_when(
    mean_d_attitude > mean_d_behavior ~ "Higher",
    mean_d_attitude == mean_d_behavior ~ "Same",
    mean_d_attitude < mean_d_behavior ~ "Lower"
  )) |>
  count(comparison) |>
  rename(Comparison = comparison, Count = n)
binom.test(36, (36 + 12 + 1), 0.5)
# This code could stand to be cleaned up a lot
```

Forest Plot (Figure):

```{r forest_plot}
head(dat_for_forest_plot) # checking we've already created subset (chunk above)
# overall effect size
overall_forest <- dat_for_forest_plot |>
  split(~scale_type) |>
  map(map_robust)


dat_for_forest_plot <- dat_for_forest_plot |> 
  add_row(study_names = "Overall (Attitudes)",
          d = overall_forest[[1]]$beta,
          se_d = overall_forest[[1]]$se,
          scale_type = "attitudes",
          unique_paper_id = NA) |>
  add_row(study_names = "Overall (Behavior)",
          d = overall_forest[[2]]$beta,
          se_d = overall_forest[[2]]$se,
          scale_type = "behavior",
          unique_paper_id = NA) |>
  mutate(index = row_number()) |>
  relocate(index, .before = 1)
  
# plot 
dat_for_forest_plot |>
  ggplot(aes(y = index, x = d, xmin = d - (1.96 * se_d),
             xmax = d + (1.96 * se_d))) +  
  geom_point(size = 1) +
  geom_errorbarh(height = .1, aes(color = scale_type)) +
  geom_vline(xintercept = 0, color = "black", alpha = .5) +
  scale_x_continuous(name = expression(paste("Glass's", " ", Delta))) +
  scale_y_continuous(name = "", breaks = 1:length(dat_for_forest_plot$study_names),
                     trans = "reverse", labels = dat_for_forest_plot$study_names) + 
  ylab("Study") +
  geom_vline(xintercept = overall_forest$attitudes$beta, color = '#F8766D', lty = 'dashed') +
  geom_vline(xintercept = overall_forest$behavior$beta, color = '#00BFC4', lty = 'dashed') +
  labs(color = "Attitudes or behaviors") +
  theme_minimal() + 
  theme(axis.text.y = element_text(face = ifelse(
    dat_for_forest_plot$study_names %in% 
      c("Overall (Attitudes)", "Overall (Behavior)"), 
    "bold", "plain"), 
    margin = margin(t = 0.5, b = 0.5, unit = "cm"))) +
  ggtitle("Attitudinal and Behavioral Changes Compared")


# getting a warning message about vectorized input is not officially supported
# and results may change in future versions of ggplot2. 
# Guess we'll hope they don't? :)
```

Behavioral measurement has become more common over time, particularly from 2010 onward. 
```{r behavioral_outcomes_by_decade}
range(dat$year)

# how many studies in each decade
dat |> group_by(decade) |> study_count()

tab <- merge(x = dat |> group_by(decade) |> study_count(),
             y = dat |> group_by(decade, scale_type) |> summarise(n = n())) 
# print tab
tab

#reshape and make latex table
tab |>
  pivot_wider(names_from = scale_type, values_from = n) |>
  mutate(ratio = attitudes/behavior) |>
  knitr::kable(format = 'latex')

# what was the earliest study to measure behavior as we conceive it?
dat |> filter(scale_type == 'behavior') |> 
  arrange(year) |> 
  select(author, year, paper_title) |> head()

## what if we just do this for behaviors?
dat |>
  ggplot(aes(x = year, color = behavior_type)) + 
  geom_line(stat = 'count') + 
  labs(x = "Year", 
       y = "Count", 
       color = "Behavior type",
       title = "Categories of behavioral outcomes over time") +
  scale_x_continuous(n.breaks = 10) +
  scale_y_continuous(n.breaks = 10) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```


