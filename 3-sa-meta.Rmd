---
title: "3-SA-meta-analyis.Rmd"
author: "Seth Green"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=F, echo=F}
rm(list = ls())
library(dplyr, warn.conflicts = F)
library(metafor, quietly = T)
library(ggplot2, warn.conflicts = F)
library(ggrepel, warn.conflicts = F)
library(purrr)
library(stringr)
library(tidyr, warn.conflicts = F)

source('./functions/dplot.R')
source('./functions/sum_lm.R')
# NOTE ON SUM_LM: 
# `sum_lm(dat, d, se_d, coef_only = T)` = `summary(lm(formula = d ~ se_d, 
#                                          data = dat))$coefficients`
```

```{r load_data, include=F, echo=F}
# read in data, add in two useful variables
# labels that paste together author and year for plots;  
# reading later results);
# add attitudes_behaviors (for studies that have both), one or the other;
# new var for random assignment (probably should remove 'contains randomization')

dat <- readRDS(file = './data/sa_meta_data_for_analysis.rds') %>%
  select(unique_study_id, scale_type, everything()) %>%
  mutate(labels = paste(tools::toTitleCase(word(author)), year),
         ra = ifelse(study_design == 'rct' | study_design == 'pragmatic rct', 
                     TRUE,
                     FALSE)) %>%
  group_by(unique_study_id) %>%
  mutate(
    attitudes_behaviors = case_when(
      all(c('attitudes', 'behavior') %in% scale_type) ~ 0,
      scale_type == 'attitudes' ~ 1,
      scale_type == 'behavior' ~ 2)) %>%
  ungroup() 

behavioral_data <- dat %>% filter(scale_type == 'behavior')

```

# General Methods 

**Initial data exploration**
```{r initial_exploration}

# first, wht is the relationship between effect size and se?

sum_lm(dat, d, se_d,coefs_only = T)

# by study type?
dat %>% 
  split(.$study_design) %>% 
  map(.f = ~sum_lm(y = d, x = se_d, dat = .))
# visualize this?
dat %>% 
  split(.$study_design) %>% 
  map(.x = ., .f = ~dplot(sa_data = ., dot_size = 2, condense = F,
                          dot_informative = T))
# TODO: modify this so that text is lined up properly and so that color = 
# attitude/behavior
# 
# so basically there's little relationship in the quasi and pragmatic rcts -- 
# there is actually a negative relationship in the quasi experimental studies? -- 
# but a meaningful relationship in the RCTs and pre-post studies. 
# What if we separate into randomized and not-randomized

# now, an overall meta-analysis

robust(x = rma(yi = d, vi = var_d, data = dat),
       cluster = dat$unique_study_id)

```

### By study type:

"Analysis of subgroups or subsets: We will compare subsets of the data according to classifications of evaluation methodology (i.e., observational vs. quasi-experimental vs. experimental methods)..."

```{r study_type}
dat %>% 
  split(dat$study_design) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
```

### By outcome type:

"... and of outcome measurement (i.e., general behavior indices vs. perpetration behavior, and attitudinal measurement vs. behavioral measurement)."

```{r outcome_type}
# First, behavior vs attitudes:
dat %>% 
  split(dat$scale_type) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
# behavioral effects are *much* smaller than attitude results


table(dat$behavior_type)
# TODO: triple-check that thesse are right.

# how do effect sizes compare across behavioral types?
dat %>% 
  split(.$behavior_type) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id)) 
# this suggests that moving the needle on perpetration is effectively unsolved problem

# What about just the RCTs?
behavioral_rcts <- dat %>%
  filter(scale_type == 'behavior', 
         study_design == 'rct') %>%
  select(author, year, paper_title, behavior_type, scale_name, 
         intervention_name,d, se_d, n_t_post, n_c_post, everything())
  
behavioral_rcts %>%
  split(behavioral_rcts$behavior_type) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id)) 

# in general, the effects on victimization and  perpetration are larger in the rcts, 
# which is encouraging (and surprising to me).

```

* Evaluate the overall effect size of behavioral outcomes for all of the studies in the dataset, both in the short- and in the long-term. 

```{r behavioral_over_time}

robust(x = rma(yi = d, vi = var_d, data = behavioral_data), 
       cluster = behavioral_data$unique_study_id)

# meta-analysis with a split for delay, yes, no
behavioral_data %>% 
  split(as.factor(behavioral_data$delay > 0)) %>%
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# a delay leads to substantial decline

```

* Compare the effect size of behavioral outcomes for experimental and quasi-experimental studies vs. non-experimental observational studies, both in the short- and in the long-term.

```{r experimental_quasi_vs_non_experimental_delay_and_not}
behavioral_data %>% 
  mutate(study_group = if_else
         (study_design %in% c('quasi-experimental', 'pragmatic rct', 'rct'),
           'randomized and quasis',  'observational'),
         yes_delay = if_else(delay == 0, '& no delay', '& delay')) %>%
  split(list(.$study_group, .$yes_delay)) %>%
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# TODO: what is driving the large effect sizes 
# for no delay quasi and randomized studies?
# what even does no delay measurement mean in this context? Presumably there's no delay
# from onset of treatment rather than conclusion otherwise you couldn't measure 
# anything behavioral, unless it's entirely driven by 'intent' stuff
```

* Compare the effect size of behavioral outcomes for studies with random assignment vs. quasi-experimental studies, both in the short- and in the long-term. 

```{r experimental_stricti_vs_non_experimental_delay_and_not}
behavioral_data %>% 
  mutate(study_group = if_else(
    study_design %in% c('pragmatic rct', 'rct'), 'randomized', 'observational'),) %>%
    mutate(yes_delay = if_else(delay == 0, '& no delay', '& delay')) %>%
  split(list(.$study_group, .$yes_delay)) %>%
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
# TODO: This and the above chunk are syntactically elegant but maybe there's an easier way to present results; really just need the model Results. 
# this is unexpectedly complex
```

* Evaluate at the effect size of perpetration behavioral outcomes for only studies with random assignment, both in the short- and in the long-term. 

```{r perpetration outcomes}

rct_perp <- behavioral_rcts %>% 
  filter(behavior_type == 'perpetration')

# now an overall meta. behavioral data need time to accumulate 
# so instead of delay, yes/no, how about delay > 1 month (30 days)

rct_perp %>%
  split(.$delay > 30) %>%
  map(.f = ~robust(rma(yi = .x$d, vi = .x$var_d), 
                   cluster = .x$unique_study_id))
# no difference

rct_perp %>% ggplot(mapping = aes(x = delay, y = d)) + 
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_minimal()

# one story here is the range of Ds -- what's this -0.5 increase in perpetration?
# TODO: double-check that we coded this in the right direction

rct_perp %>% filter(delay >30) %>%
ggplot(mapping = aes(x = se_d, y = d)) + 
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_minimal()
# a strong relationship

```

* Compare the effect size of behavioral outcomes and attitudinal outcomes, both in the short- and long-term, among the quasi-experimental and randomly-assigned studies. (The covariation of attitudes and behaviors will be assessed in the full sample of studies.)

```{r}

rcts_and_quasi <- dat %>% 
  filter(study_design %in% c('rct', 'pragmatic_rct', 'quasi-experimental')) 

# overall effect size difference between attitudes and behaviors?
rcts_and_quasi %>%
  sum_lm(d, scale_type)

# meta-analyze attitudes and behaviors separately, short and long term
rcts_and_quasi %>% 
    mutate(yes_delay = if_else(delay == 0, '& no delay', '& delay')) %>%
  split(list(.$scale_type, .$yes_delay)) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

```

What is the association between attitudes and behaviors (temporal match) – this answers our question of ‘should we care about attitudes?’

```{r}
has_both <- dat %>% 
  filter(attitudes_behaviors == 0) %>%
  group_by(unique_study_id, scale_type) %>%
  mutate(mean_d = mean(d), 
         mean_var_d = mean(var_d), 
         mean_se_d = mean(se_d)) %>%
  select(author, year, paper_title, unique_study_id, intervention_name,
         study_design, mean_d, mean_var_d, mean_se_d,
         ra, labels, scale_type) %>%  
  slice(1) %>% 
  pivot_wider(
    id_cols = c(author, year, paper_title, unique_study_id,
                intervention_name,
                unique_study_id, study_design, ra, labels),
    names_from = c(scale_type), 
    values_from = c(mean_d, mean_var_d, mean_se_d))
cor.test(x = has_both$mean_d_attitudes, 
         y = has_both$mean_d_behavior)

# by study type?
has_both %>% 
  split(.$ra) %>%
  map(~cor.test(.$mean_d_attitudes, .$mean_d_behavior))

# what's the slope of these lines
has_both %>% sum_lm(mean_d_behavior, mean_d_attitudes)
has_both %>% filter(study_design == 'rct') %>% sum_lm(mean_d_behavior, mean_d_attitudes)
```


### Plotting
```{r plotting}

# overall linear plot
ggplot(data = dat, mapping = aes(x = se_d, y = d)) +
  geom_point() +
  geom_smooth(method = 'lm') + 
  theme_minimal()

#### Visualizing this: plot D and SE, with color corresponding to
#### study type and shape corresponding to lab or field
dplot(condense = T)

# I had really thought there was more of a relationship
dplot(condense = F)
# not especially informative

## Relationship between attitudes and behaviors 

has_both %>%
  select(author, year, mean_d_attitudes, mean_d_behavior) %>%
  ggplot(mapping = aes(x = mean_d_attitudes, y = mean_d_behavior)) +
  geom_point(size = 3) + 
  geom_smooth(method = 'lm', se = F, lty = 'dashed') + 
  theme_minimal()

# now same with RCTs 
has_both %>% filter(study_design == 'rct') %>% 
  select(author, year, mean_d_attitudes, mean_d_behavior, labels) %>%
  ggplot(mapping = aes(x = mean_d_attitudes, y = mean_d_behavior)) +
  geom_point(size = 3) + 
  geom_smooth(aes(fill = NULL), lty = "dashed", fullrange = TRUE, 
              method = "lm",
              show.legend = FALSE, alpha = .1, se = F) + 
  geom_label_repel(mapping = aes(label = labels)) +
  theme_minimal()
```
