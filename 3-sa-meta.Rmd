---
title: "3-SA-meta-analyis.Rmd"
author: "Seth Green"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
editor_options: 
  chunk_output_type: console
---

### Overview

This document will work through our results, and its aim is to both reflect the pre-analyis plan as it was written in 2018 and the most up-to-date version of the text. Everything in our pre-analsis plan will be included in either the main results section or an appendix, but not necessarily in the order it was drafted up.

This document will precede chunks with quotes prepended either a "*paper*" or a "*PAP* to denote whether the text is from the paper or the pre-analysis plan.

### Setup

```{r setup, include=F, echo=F}
rm(list = ls())
library(dplyr, warn.conflicts = F)
library(metafor, quietly = T)
library(ggplot2, warn.conflicts = F)
library(ggrepel, warn.conflicts = F)
library(purrr)
library(stringr)
library(tidyr, warn.conflicts = F)

source('./functions/dplot.R')
source('./functions/sum_lm.R')
# NOTE ON SUM_LM: 
# `sum_lm(dat, d, se_d, coef_only = T)` = `summary(lm(formula = d ~ se_d, 
#                                          data = dat))$coefficients`
```

```{r load_data, include=F, echo=F}
# read in data, add in two useful variables
# labels that paste together author and year for plots;  
# add attitudes_behaviors (for studies that have both), one or the other;

raw_dat <- readRDS(file = './data/sa_meta_data_for_analysis.rds')
dat <- raw_dat %>%
  select(unique_study_id, scale_type, everything()) %>%
  mutate(labels = paste(tools::toTitleCase(word(author)), year),
         ra = ifelse(study_design == 'rct', TRUE, FALSE),
         yes_delay = as.factor(delay > 0)) %>%
  group_by(unique_study_id) %>%
  mutate(
    attitudes_behaviors = case_when(
      all(c('attitudes', 'behavior') %in% scale_type) ~ 0,
      scale_type == 'attitudes' ~ 1,
      scale_type == 'behavior' ~ 2)) %>%
  ungroup() 


```

## Results 

### Overall results and publication bias 

*paper*: "We estimate an overall effect size of..."
```{r overall_meta}

robust(x = rma(yi = d, vi = var_d, data = dat),
       cluster = dat$unique_study_id)
```

*paper*: "Across the sample as a whole, we do not observe a statistically significant relationship between effect sizes and standard errors"
TODO: insert text about variation by publication type
```{publication_bias_overall}
sum_lm(dat, d, se_d, coefs_only = T)

# by study type?
dat %>% 
  split(.$study_design) %>% 
  map(.f = ~sum_lm(y = d, x = se_d, dat = .))
```

## Heterogeneity across designs and outcomes

### By study type:

*pap*: "Analysis of subgroups or subsets: We will compare subsets of the data according to classifications of evaluation methodology (i.e., observational vs. quasi-experimental vs. experimental methods) and of outcome measurement"

*paper*: "The picture becomes murkier, however, when we break effect size estimates down by study design and attitudes vs. behaviors"

```{r study_type}

# main body of table
dat %>%   
  split(list(.$scale_type, .$study_design)) %>%
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# behavior vs attitudes for the 'overall' row
dat %>% 
  split(.$scale_type) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# study designs for the "overall" column
dat %>% 
      split(.$study_design) %>% 
      map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
# overall/overall text comes from overall_meta chunk

# TODO (optional): extract the needed elements from the list and 
# format it into a nice table rather than filling in table by hand
```

*paper* (footnote): "In keeping with the consistency between available meta-analyses' estimates, we also observe little relationship between effect size and year of publication"

```{r effect_size_and_pub_year}
dat %>% sum_lm(y = d, x = year)
# this graph isn't in the paper but making sure there's no obvious relationship:
dat %>% ggplot(aes(x = year,y = d)) + geom_point() +
  stat_smooth(method = "lm") + theme_minimal() +
  ggtitle('Effect sizes over time')
```

## Do effects attenuate over time?

*pap* Evaluate the overall effect size of behavioral outcomes for all of the studies in the dataset, both in the short- and in the long-term. 

```{r do_effect_sizes_decay}

# split for delay and behaviors/attitudes 
dat %>% split(list(.$scale_type, as.factor(.$delay > 0))) %>%
                map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

 # get overall averages for categories
dat %>% split(.$scale_type)  %>% 
  map(.f = ~sum_lm(y = d, x = year, dataset = .))

# split meta-analysis by delay or not:
dat %>% split(.$yes_delay) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# split for delay and behavioral categories
dat %>% 
  filter(scale_type == 'behavior') %>% 
  split(list(.$behavior_type, .$yes_delay)) %>%
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
```

### By outcome type:

*pap*"...(i.e., general behavior indices vs. perpetration behavior, and attitudinal measurement vs. behavioral measurement)."

## A closer look at behavioral outcomes

### Do attitudinal changes predict behavioral changes?

*pap*: "What is the association between attitudes and behaviors (temporal match) – this answers our question of ‘should we care about attitudes?’"

```{r}
has_both <- dat %>% 
  filter(attitudes_behaviors == 0) %>%
  group_by(unique_study_id, scale_type) %>%
  mutate(mean_d = mean(d), 
         mean_var_d = mean(var_d), 
         mean_se_d = mean(se_d)) %>%
  select(author, year, paper_title, unique_study_id, intervention_name,
         study_design, mean_d, mean_var_d, mean_se_d,
         ra, labels, scale_type) %>%  
  slice(1) %>% 
  pivot_wider(
    id_cols = c(author, year, paper_title, unique_study_id,
                intervention_name,
                unique_study_id, study_design, ra, labels),
    names_from = c(scale_type), 
    values_from = c(mean_d, mean_var_d, mean_se_d))

cor.test(x = has_both$mean_d_attitudes, 
         y = has_both$mean_d_behavior)

# by study type?
has_both %>% 
  split(.$ra) %>%
  map(~cor.test(.$mean_d_attitudes, .$mean_d_behavior))

# what's the slope of these lines
has_both %>% sum_lm(mean_d_behavior, mean_d_attitudes)
has_both %>% filter(study_design == 'rct') %>% sum_lm(mean_d_behavior, mean_d_attitudes)
```

### Forest Plot (Figure)
```{forest_plot}
dat_for_forest_plot <- raw_dat %>% 
  select(unique_study_id, scale_type, everything()) %>%
  group_by(unique_study_id) %>%
  mutate(
    attitudes_behaviors = case_when(
      all(c('attitudes', 'behavior') %in% scale_type) ~ 0,
      scale_type == 'attitudes' ~ 1,
      scale_type == 'behavior' ~ 2)) %>%
  ungroup()  %>%
  filter(study_design == 'rct') %>%
  mutate(study_names = paste0(tools::toTitleCase(word(author)), " ",
                         year, " ", "(", scale_type, ")")) %>%
  filter(attitudes_behaviors == 0) %>%
  group_by(unique_paper_id, scale_type) %>%
  mutate(d = mean(d), 
         var_d = mean(var_d),
         se_d = mean(se_d)) %>%
  slice(1) %>%
  ungroup(scale_type) %>% 
  mutate(mean_se = mean(se_d)) %>%
  arrange(desc(mean_se)) %>%
  ungroup() %>%
  mutate(index = row_number()) %>%
  select(index, study_names, d, se_d, scale_type, unique_paper_id, behavior_type)

# overall effect size
overall <- dat_for_forest_plot %>%
  split(.$scale_type) %>%
  map(~robust(x = rma(yi = .$d,  sei = .$se_d), 
              cluster = .$unique_paper_id))
# plot 

p <- dat_for_forest_plot %>%
  ggplot(mapping = aes(y = index, x = d, xmin = d - (1.96 * se_d),
                       xmax = d + (1.96 * se_d))) +  
           geom_point(size = 1) +
  geom_errorbarh(height = .1, aes(color = scale_type)) +
  geom_vline(xintercept = 0, 
             color = "black",  alpha = .5) +
  scale_x_continuous(name = expression(paste("Glass's", " ", Delta))) +
  scale_y_continuous(name = "", , breaks=1:40, # , trans = "reverse"
                     labels = dat_for_forest_plot$study_names) + 
  ylab("Study") +
  geom_vline(xintercept = overall$attitudes$beta, color = '#F8766D', lty = 'dashed') +
  geom_vline(xintercept = overall$behavior$beta, color = '#00BFC4', lty = 'dashed') +
  labs(color = "Attitudes or behaviors") +
theme_minimal() + 
  theme(axis.text.y = element_text(face = "bold"))
p
png(filename = './results/4-ggplot-forest-plot.png', width = 1920/2, height = 1080/2)
p
dev.off()
# what if we limit this just to perpetration and victimization outcomes?
# TODO: this is complex, but group studies together and then drop them if 
# behavior type = bystander or volunteer

# This was really useful for figuring out colors and such: `ggplot_build(p)$data`

# TODO: create another point at the bottom that's the overall effect size and
# SE, a la the bottom point you get from the stata equivalent. 

# Plus just make it nicer overall
```

### Assessing differences between categories of behavioral outcomes
I *believe* that this is duplicative
```{r heterogeneity_study_design_behavior_type}
# split for RA
dat %>% 
  split(.$ra) %>%
   map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# split by both RA and behavior type
dat %>% 
  split(list(.$ra, .$behavior_type)) %>%
   map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

dat %>% 
  split(.$behavior_type) %>%
   map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

```

