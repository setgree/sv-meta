---
title: "3-SA-meta-analyis.Rmd"
author: "Seth Green"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=F, echo=F}
rm(list = ls())
library(dplyr, warn.conflicts = F)
library(metafor, quietly = T)
library(ggplot2, warn.conflicts = F)
library(ggrepel, warn.conflicts = F)
library(purrr)
library(stringr)
library(tidyr, warn.conflicts = F)

source('./functions/dplot.R')
source('./functions/sum_lm.R')
# NOTE ON SUM_LM: 
# `sum_lm(dat, d, se_d, coef_only = T)` = `summary(lm(formula = d ~ se_d, 
#                                          data = dat))$coefficients`
```

```{r load_data, include=F, echo=F}
# read in data, add in two useful variables
# labels that paste together author and year for plots;  
# reading later results);
# add attitudes_behaviors (for studies that have both), one or the other;
# new var for random assignment (probably should remove 'contains randomization')

dat <- readRDS(file = './data/sa_meta_data_for_analysis.rds') %>%
  select(unique_study_id, scale_type, everything()) %>%
  mutate(labels = paste(tools::toTitleCase(word(author)), year),
         ra = ifelse(study_design == 'rct', TRUE, FALSE),
         yes_delay = as.factor(delay > 0)) %>%
  group_by(unique_study_id) %>%
  mutate(
    attitudes_behaviors = case_when(
      all(c('attitudes', 'behavior') %in% scale_type) ~ 0,
      scale_type == 'attitudes' ~ 1,
      scale_type == 'behavior' ~ 2)) %>%
  ungroup() 


```

## Overall results and publication bias 

```{r initial_exploration}

# first, what is the relationship between effect size and se?

sum_lm(dat, d, se_d, coefs_only = T)

# by study type?
dat %>% 
  split(.$study_design) %>% 
  map(.f = ~sum_lm(y = d, x = se_d, dat = .))

# strong evidence of publication bias in the pre-post studies
# now, an overall meta-analysis

robust(x = rma(yi = d, vi = var_d, data = dat),
       cluster = dat$unique_study_id)

```


## Heterogeneity across designs and outcomes

### By study type:

"Analysis of subgroups or subsets: We will compare subsets of the data according to classifications of evaluation methodology (i.e., observational vs. quasi-experimental vs. experimental methods)..."

```{r study_type}
# group the pragmatic RCTs with the RCTs for now; as robustness check, 
# group them with the quasi-experiments, or ungroup them; fundamentally the same
# results, but risks distracting from main conclusions in the paper
# also the effect sizes between RCTs, pragmatic, & quasi-experiments are
# really similar so adding the pragmatics to the quasi group affects overall 
# estimates basically not at all (see robustness check)
dat %>% 
      split(.$study_design) %>% 
      map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
```

### By outcome type:

"... and of outcome measurement (i.e., general behavior indices vs. perpetration behavior, and attitudinal measurement vs. behavioral measurement)."

```{r outcome_type}

# FOR INCLUSION in PAPER: divide into observational, quasi, and RCT
# and split into behavioral/attitudes and select
dat %>%   
  split(list(.$scale_type, .$study_design)) %>%
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# behavior vs attitudes for the 'overall' column
dat %>% 
  split(.$scale_type) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# behavioral effects are *much* smaller than attitude results

# TODO (optional): extract the needed elements from the list and 
# format it into a nice table rather than filling in table by hands
```


## Do effects attenuate over time?

* Evaluate the overall effect size of behavioral outcomes for all of the studies in the dataset, both in the short- and in the long-term. 

```{r results_over_time}

dat %>% sum_lm(y = d, x = delay) # nothing obvious there
# didn't pre-register this, but year of publication and delta; 
ggplot(dat, aes(x = year, y = d)) + 
  stat_smooth(method = "lm") + geom_point()  # nothing obvious
dat %>% split(.$scale_type)  %>% 
  map(.f = ~sum_lm(y = d, x = year, dataset = .))

# split meta-analysis by delay or not:
dat %>% split(.$yes_delay) %>% 
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
# stronger relationship

# split for delay and behaviors/attitudes
dat %>% split(list(.$scale_type, as.factor(.$delay > 0))) %>%
                map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# split for delay and behavioral categories
dat %>% 
  filter(scale_type == 'behavior') %>% 
  split(list(.$behavior_type, .$yes_delay)) %>%
  map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))
```

## A closer look at behavioral outcomes

### Do attitudinal changes predict behavioral changes?

What is the association between attitudes and behaviors (temporal match) – this answers our question of ‘should we care about attitudes?’

```{r}
has_both <- dat %>% 
  filter(attitudes_behaviors == 0) %>%
  group_by(unique_study_id, scale_type) %>%
  mutate(mean_d = mean(d), 
         mean_var_d = mean(var_d), 
         mean_se_d = mean(se_d)) %>%
  select(author, year, paper_title, unique_study_id, intervention_name,
         study_design, mean_d, mean_var_d, mean_se_d,
         ra, labels, scale_type) %>%  
  slice(1) %>% 
  pivot_wider(
    id_cols = c(author, year, paper_title, unique_study_id,
                intervention_name,
                unique_study_id, study_design, ra, labels),
    names_from = c(scale_type), 
    values_from = c(mean_d, mean_var_d, mean_se_d))

cor.test(x = has_both$mean_d_attitudes, 
         y = has_both$mean_d_behavior)

# by study type?
has_both %>% 
  split(.$ra) %>%
  map(~cor.test(.$mean_d_attitudes, .$mean_d_behavior))

# what's the slope of these lines
has_both %>% sum_lm(mean_d_behavior, mean_d_attitudes)
has_both %>% filter(study_design == 'rct') %>% sum_lm(mean_d_behavior, mean_d_attitudes)
```

### Forest Plot 
```{forest_plot}
dat_for_forest_plot <- readRDS(file = './data/sa_meta_data_for_analysis.rds') %>%
  select(unique_study_id, scale_type, everything()) %>%
  group_by(unique_study_id) %>%
  mutate(
    attitudes_behaviors = case_when(
      all(c('attitudes', 'behavior') %in% scale_type) ~ 0,
      scale_type == 'attitudes' ~ 1,
      scale_type == 'behavior' ~ 2)) %>%
  ungroup()  %>%
  filter(study_design == 'rct') %>%
  mutate(study_names = paste0(tools::toTitleCase(word(author)), " ",
                         year, " ", "(", scale_type, ")")) %>%
  filter(attitudes_behaviors == 0) %>%
  group_by(unique_paper_id, scale_type) %>%
  mutate(d = mean(d), 
         var_d = mean(var_d),
         se_d = mean(se_d)) %>%
  slice(1) %>%
  ungroup(scale_type) %>% 
  mutate(mean_se = mean(se_d)) %>%
  arrange(desc(mean_se)) %>%
  ungroup() %>%
  mutate(index = row_number()) %>%
  select(index, study_names, d, se_d, scale_type, unique_paper_id, behavior_type)

# overall effect size
overall <- dat_for_forest_plot %>%
  split(.$scale_type) %>%
  map(~robust(x = rma(yi = .$d,  sei = .$se_d), 
              cluster = .$unique_paper_id))
# plot 

p <- dat_for_forest_plot %>%
  ggplot(mapping = aes(y = index, x = d, xmin = d - (1.96 * se_d),
                       xmax = d + (1.96 * se_d))) +  
           geom_point(size = 1) +
  geom_errorbarh(height = .1, aes(color = scale_type)) +
  geom_vline(xintercept = 0, 
             color = "black",  alpha = .5) +
  scale_x_continuous(name = expression(paste("Glass's", " ", Delta))) +
  scale_y_continuous(name = "", , breaks=1:40, # , trans = "reverse"
                     labels = dat_for_forest_plot$study_names) + 
  ylab("Study") +
  geom_vline(xintercept = overall$attitudes$beta, color = '#F8766D', lty = 'dashed') +
  geom_vline(xintercept = overall$behavior$beta, color = '#00BFC4', lty = 'dashed') +
  labs(color = "Attitudes or behaviors") +
theme_minimal() + 
  theme(axis.text.y = element_text(face = "bold"))
p
png(filename = './results/4-ggplot-forest-plot.png', width = 1920/2, height = 1080/2)
p
dev.off()
# what if we limit this just to perpetration and victimization outcomes?
# TODO: this is complex, have to group studies together and then drop them if 
# behavior type = bystander or volunteer

# This was really useful for figuring out colors and such: `ggplot_build(p)$data`

# TODO: create another point at the bottom that's the overall effect size and
# SE, a la the bottom point you get from the stata equivalent. 

# Plus just make it nicer overall
```

### Assessing differences between categories of behavioral outcomes

```{r heterogeneity_study_design_behavior_type}
# split for RA
dat %>% 
  split(.$ra) %>%
   map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# split by both RA and behavior type
dat %>% 
  split(list(.$ra, .$behavior_type)) %>%
   map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

dat %>% 
  split(.$behavior_type) %>%
   map(.f = ~robust(x = rma(yi = .x$d, vi = .x$var_d),
       cluster = .x$unique_study_id))

# We note from this that effect sizes are basically the same for us as they are for 
# Andersoon 2005 paper; is there a relationship between publication year and 
# either average behavioral or attitudinal results?
```

